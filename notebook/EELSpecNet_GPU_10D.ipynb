{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 3017,
     "status": "ok",
     "timestamp": 1634265336123,
     "user": {
      "displayName": "shayan mousavi masouleh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02242213354548196400"
     },
     "user_tz": 240
    },
    "id": "XsDqK4Cp_lfw"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shmouses/EELSpecNet/blob/main/article/EELSpecNet_GPU_10D.ipynb)  \n",
    "\n",
    "# **EELSpecNet**\n",
    "\n",
    "Dependencies in the requirements.txt file\n",
    "\n",
    "Main code generating EELSpecNet Neural Networks with different depths and training them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2817,
     "status": "ok",
     "timestamp": 1634265333113,
     "user": {
      "displayName": "shayan mousavi masouleh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02242213354548196400"
     },
     "user_tz": 240
    },
    "id": "VuABs0YP1Rd6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os \n",
    "import tensorflow_datasets as tfds\n",
    "import copy\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.special import wofz, erf\n",
    "import matplotlib.pyplot as plt\n",
    "import notebook\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "tnp.experimental_enable_numpy_behavior()\n",
    "\n",
    "import notebook\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook \n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1634265336278,
     "user": {
      "displayName": "shayan mousavi masouleh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02242213354548196400"
     },
     "user_tz": 240
    },
    "id": "hUxTN4Wo1p1O",
    "outputId": "94635d47-a132-4373-e6de-4eaa460706e6"
   },
   "outputs": [],
   "source": [
    "# Specific to the use of GPUs in Google Colab\n",
    "\n",
    "%tensorflow_version 2.x\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1634265336281,
     "user": {
      "displayName": "shayan mousavi masouleh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02242213354548196400"
     },
     "user_tz": 240
    },
    "id": "hBqn57oB1qEX"
   },
   "source": [
    "**Neural Networks design**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1634265336749,
     "user": {
      "displayName": "shayan mousavi masouleh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02242213354548196400"
     },
     "user_tz": 240
    },
    "id": "2pvO8gFO1qHH"
   },
   "outputs": [],
   "source": [
    "class EELSpecNetModel_CNN_10D(tf.keras.Model):\n",
    "    \n",
    "    \n",
    "    def __init__(self, ene_dim):\n",
    "        super(EELSpecNetModel_CNN_10D, self).__init__()\n",
    "        \n",
    "        kerl_size = 4\n",
    " \n",
    "        self.conv_1024x64 = tf.keras.layers.Conv2D(64, (1,kerl_size), strides = (1,2),\n",
    "                                                   activation = 'relu', padding = 'same',\n",
    "                                                   kernel_initializer='random_uniform')\n",
    " \n",
    "        self.conv_512x128 = tf.keras.layers.Conv2D(128, (1,kerl_size), strides = (1,2),\n",
    "                                                   activation = 'relu', padding = 'same',\n",
    "                                                   kernel_initializer='random_uniform')\n",
    " \n",
    "        self.conv_256x256 = tf.keras.layers.Conv2D(256, (1,kerl_size), strides = (1,2),\n",
    "                                                   activation = 'relu',padding = 'same',\n",
    "                                                   kernel_initializer='random_uniform')\n",
    " \n",
    "        self.conv_128x512 = tf.keras.layers.Conv2D(512, (1,kerl_size), strides = (1,2),\n",
    "                                                   activation = 'relu', padding = 'same',\n",
    "                                                   kernel_initializer='random_uniform')\n",
    " \n",
    "        self.conv_64x1024 = tf.keras.layers.Conv2D(1024, (1,kerl_size), strides = (1,2),\n",
    "                                                   activation = 'relu', padding = 'same',\n",
    "                                                   kernel_initializer='random_uniform')\n",
    " \n",
    "        self.conv_32x2048 = tf.keras.layers.Conv2D(2048, (1,kerl_size), strides = (1,2),\n",
    "                                                   activation = 'relu',padding = 'same',\n",
    "                                                   kernel_initializer='random_uniform')\n",
    " \n",
    "        self.conv_16x2048 = tf.keras.layers.Conv2D(2048, (1,kerl_size), strides = (1,2),\n",
    "                                                   activation = 'relu', padding = 'same',\n",
    "                                                   kernel_initializer='random_uniform')\n",
    " \n",
    "        self.conv_8x2048 = tf.keras.layers.Conv2D(2048, (1,kerl_size), strides = (1,2),\n",
    "                                                  activation = 'relu', padding = 'same',\n",
    "                                                  kernel_initializer='random_uniform')\n",
    " \n",
    "        self.conv_4x2048 = tf.keras.layers.Conv2D(2048, (1,kerl_size), strides = (1,2),\n",
    "                                                  activation = 'relu',padding = 'same',\n",
    "                                                  kernel_initializer='random_uniform')\n",
    " \n",
    "        self.conv_2x2048 = tf.keras.layers.Conv2D(2048, (1,kerl_size), strides = (1,2),\n",
    "                                                  activation = 'relu', padding = 'same',\n",
    "                                                  kernel_initializer='random_uniform')\n",
    "        \n",
    "        #=======================================================================\n",
    " \n",
    "        self.deconv_4x2048 = tf.keras.layers.Conv2DTranspose(2048, (1,kerl_size), strides = (1,2),\n",
    "                                                             activation = 'relu', padding = 'same',\n",
    "                                                             kernel_initializer='random_uniform')\n",
    " \n",
    "        self.deconv_8x2048 = tf.keras.layers.Conv2DTranspose(2048, (1,kerl_size), strides = (1,2),\n",
    "                                                             activation = 'relu', padding = 'same',\n",
    "                                                             kernel_initializer='random_uniform')\n",
    " \n",
    "        self.deconv_16x2048 = tf.keras.layers.Conv2DTranspose(2048, (1,kerl_size), strides = (1,2),\n",
    "                                                              activation = 'relu', padding = 'same',\n",
    "                                                              kernel_initializer='random_uniform')\n",
    " \n",
    "        self.deconv_32x2048 = tf.keras.layers.Conv2DTranspose(2048, (1,kerl_size), strides = (1,2),\n",
    "                                                              activation = 'relu', padding = 'same',\n",
    "                                                              kernel_initializer='random_uniform')\n",
    " \n",
    "        self.deconv_64x1024 = tf.keras.layers.Conv2DTranspose(1024, (1,kerl_size), strides = (1,2),\n",
    "                                                              activation = 'relu', padding = 'same',\n",
    "                                                              kernel_initializer='random_uniform')\n",
    " \n",
    "        self.deconv_128x512 = tf.keras.layers.Conv2DTranspose(512, (1,kerl_size), strides = (1,2),\n",
    "                                                              activation = 'relu', padding = 'same',\n",
    "                                                              kernel_initializer='random_uniform')\n",
    " \n",
    "        self.deconv_256x256 = tf.keras.layers.Conv2DTranspose(256, (1,kerl_size), strides = (1,2),\n",
    "                                                              activation = 'relu', padding = 'same',\n",
    "                                                              kernel_initializer='random_uniform')\n",
    "        \n",
    "        self.deconv_512x128 = tf.keras.layers.Conv2DTranspose(128, (1,kerl_size), strides = (1,2),\n",
    "                                                              activation = 'relu', padding = 'same',\n",
    "                                                              kernel_initializer='random_uniform')\n",
    "        \n",
    "        self.deconv_1024x64 = tf.keras.layers.Conv2DTranspose(64, (1,kerl_size), strides = (1,2),\n",
    "                                                              activation = 'relu', padding = 'same',\n",
    "                                                              kernel_initializer='random_uniform')\n",
    "        \n",
    "        self.deconv_2048x1 = tf.keras.layers.Conv2DTranspose(1, (1,kerl_size), strides = (1,2),\n",
    "                                                             activation = 'tanh', padding = 'same',\n",
    "                                                             kernel_initializer='random_uniform')\n",
    "        \n",
    "        self.concat = tf.keras.layers.concatenate\n",
    "        self.relu = tf.keras.activations.relu\n",
    "        \n",
    "    \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        enc_1024x64 = self.conv_1024x64(inputs)\n",
    "        \n",
    "        enc_512x128 = self.conv_512x128(enc_1024x64)\n",
    "        \n",
    "        enc_256x256 = self.conv_256x256(enc_512x128)\n",
    "        \n",
    "        enc_128x512 = self.conv_128x512(enc_256x256)\n",
    "        \n",
    "        enc_64x1024 = self.conv_64x1024(enc_128x512)\n",
    "        \n",
    "        enc_32x2048 = self.conv_32x2048(enc_64x1024)\n",
    "        \n",
    "        enc_16x2048 = self.conv_16x2048(enc_32x2048)\n",
    "        \n",
    "        enc_8x2048 = self.conv_8x2048(enc_16x2048)\n",
    "        \n",
    "        enc_4x2048 = self.conv_4x2048(enc_8x2048)\n",
    "                \n",
    "        enc_2x2048 = self.conv_2x2048(enc_4x2048)\n",
    "        \n",
    "        #=======================================================================\n",
    " \n",
    "        dcd_4x2048 = self.deconv_4x2048(enc_2x2048)  \n",
    "        dcd_4x2048x2 = self.concat([dcd_4x2048, enc_4x2048], axis=-1)\n",
    "        \n",
    "        dcd_8x2048 = self.deconv_8x2048(dcd_4x2048x2)\n",
    "        dcd_8x2048x2 = self.concat([dcd_8x2048, enc_8x2048], axis=-1)\n",
    "                \n",
    "        dcd_16x2048 = self.deconv_16x2048(dcd_8x2048x2)\n",
    "        dcd_16x2048x2 = self.concat([dcd_16x2048, enc_16x2048], axis=-1)\n",
    "        \n",
    "        dcd_32x2048 = self.deconv_32x2048(dcd_16x2048x2)\n",
    "        dcd_32x2048x2 = self.concat([dcd_32x2048, enc_32x2048], axis=-1)\n",
    "        \n",
    "        dcd_64x1024 = self.deconv_64x1024(dcd_32x2048x2)\n",
    "        dcd_64x1024x2 = self.concat([dcd_64x1024, enc_64x1024], axis=-1)\n",
    "        \n",
    "        dcd_128x512 = self.deconv_128x512(dcd_64x1024x2)\n",
    "        dcd_128x512x2 = self.concat([dcd_128x512, enc_128x512], axis=-1)\n",
    "        \n",
    "        dcd_256x256 = self.deconv_256x256(dcd_128x512x2)\n",
    "        dcd_256x256x2 = self.concat([dcd_256x256, enc_256x256], axis=-1)\n",
    "        \n",
    "        dcd_512x128 = self.deconv_512x128(dcd_256x256x2)\n",
    "        dcd_512x128x2 = self.concat([dcd_512x128, enc_512x128], axis=-1)\n",
    "        \n",
    "        dcd_1024x64 = self.deconv_1024x64(dcd_512x128x2)\n",
    "        dcd_1024x64x2 = self.concat([dcd_1024x64, enc_1024x64], axis=-1)\n",
    "        \n",
    "        dcd_2048x1 = self.deconv_2048x1(dcd_1024x64x2)\n",
    " \n",
    "        \n",
    "        return(dcd_2048x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data for model training**  \n",
    "\n",
    "In this notebook, it is assumed that the training data (\"convolved_general_6000.npy\" and \"original_general_6000.npy\" files) are already available in the training folder. \n",
    "\n",
    "If needed the training data can be generated in the training folder executing the Generate_Training_Set.ipynb notebook. Once generated make sure the data is saved in the training folder to be properly loaded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3847,
     "status": "ok",
     "timestamp": 1634265340950,
     "user": {
      "displayName": "shayan mousavi masouleh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02242213354548196400"
     },
     "user_tz": 240
    },
    "id": "DL7GWYyQ1qJ9",
    "outputId": "2bf84f9f-23a0-4f76-a2c8-d9a8f971bf7e"
   },
   "outputs": [],
   "source": [
    "# initial data\n",
    "data_convolved_loaded = np.load(\"training/convolved_general_6000.npy\")\n",
    "tnp_convolved_loaded = tnp.asarray(data_convolved_loaded)\n",
    "\n",
    "# target data\n",
    "data_original_loaded = np.load(\"training/original_general_6000.npy\")\n",
    "tnp_original_loaded = tnp.asarray(data_original_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1634265340951,
     "user": {
      "displayName": "shayan mousavi masouleh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02242213354548196400"
     },
     "user_tz": 240
    },
    "id": "lfmU__191qM7",
    "outputId": "41c9484e-e96c-4782-ff76-dc780009fa5a"
   },
   "outputs": [],
   "source": [
    "x_dim, e_dim = np.shape(data_original_loaded)\n",
    "\n",
    "# Avoid zeros in data\n",
    "tnp_original_loaded += 0.001      \n",
    "tnp_convolved_loaded += 0.001   \n",
    "\n",
    "tnp_data_original = tnp_original_loaded.reshape((x_dim, 1, e_dim, 1))\n",
    "tnp_data_convolved = tnp_convolved_loaded.reshape((x_dim, 1, e_dim, 1))\n",
    "tnp_train_original = tnp_data_original[:, :, :, :]\n",
    "tnp_train_convolved = tnp_data_convolved[:, :, :, :] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtKeCSYM0Xmd"
   },
   "source": [
    "**Instantiate, build and train model**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40383921,
     "status": "ok",
     "timestamp": 1634314660483,
     "user": {
      "displayName": "shayan mousavi masouleh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02242213354548196400"
     },
     "user_tz": 240
    },
    "id": "v5f3Um6Q1qUU",
    "outputId": "63a40ce2-ee5a-411c-939f-8ac3a8f09fb7"
   },
   "outputs": [],
   "source": [
    "model = EELSpecNetModel_CNN_10D(2048)\n",
    "op = tf.keras.optimizers.Adam(learning_rate = 5e-5)\n",
    "model.compile(optimizer = op, loss = 'BinaryCrossentropy', metrics = ['mape','mse'])\n",
    "model.build((1,1,2048,1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "history= model.fit(tnp_train_convolved, tnp_train_original, validation_split=0.16, batch_size= 16, epochs = 1000)\n",
    "print(\"------------------------ Training done !!! ------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1634314660488,
     "user": {
      "displayName": "shayan mousavi masouleh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02242213354548196400"
     },
     "user_tz": 240
    },
    "id": "kPQfW_L1Dgoi"
   },
   "outputs": [],
   "source": [
    "model.save('model/general_6000') # Warning model size 2.44Gb - not stored in github repository\n",
    "\n",
    "# Saving training history to csv:\n",
    "hist_df = pd.DataFrame(history.history) \n",
    "hist_csv_file = 'model/history_general_6000.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)\n",
    "\n",
    "# Saving training history to numpy file:\n",
    "np.save('model/Numpy_history_general_6000.npy', history.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMWmvNSawaR/HfQ/n6EYmBp",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1FVyI0oi18sykIiDxUBP25eu5u378FQYb",
   "name": "general_GPU_10D.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
